{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a9afcf8",
   "metadata": {},
   "source": [
    "# Following Andrej Karpathy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3709b1",
   "metadata": {},
   "source": [
    "- [Reproducing GPT-2 Video](https://www.youtube.com/watch?v=l8pRSuU81PU)\n",
    "- [GPT-2 Paper by OpenAI](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fefe78",
   "metadata": {},
   "source": [
    "- te: token embedding\n",
    "- pe: position embedding\n",
    "- trying to reproduce the same schema as that of GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdd204",
   "metadata": {},
   "source": [
    "- in the MLP (Multi Layer Perceptron) implemnetation, `GELU` (Gaussian Error Linear Units) is used with *tanh* approximation\n",
    "- the tanh approximation was simply done because erf (error function) needed to compiute GELU was slow in tensorflow at the time when GELU was introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3be7e1e",
   "metadata": {},
   "source": [
    "- when implementing GPT-2, follow the same schema as that of the Hugging Face GPT-2\n",
    "- use same varibale names "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32542afd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f87feca9",
   "metadata": {},
   "source": [
    "- in hugging face, top-k is 50 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309ef54",
   "metadata": {},
   "source": [
    "## to make training faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cafb761",
   "metadata": {},
   "source": [
    "- use TF32 instead of FP32 (truncates mantissa bits) (use 'high' precision setting.)\n",
    "- it is 8 times faster\n",
    "- use powers of 2\n",
    "- use torch.autocast and torch.bfloat16\n",
    "- torch.compile.\n",
    "- use flash attention. \n",
    "  - uses incremental softmax. \n",
    "  - optimizes memory exchange. \n",
    "- use good numbers (powers of two) everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e28aab",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
